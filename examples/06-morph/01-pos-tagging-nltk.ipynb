{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5364f5ac",
   "metadata": {},
   "source": [
    "**Разметка частей речи**\n",
    "\n",
    "Евгений Борисов <esborisov@sevsu.ru>\n",
    "\n",
    "библиотека NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1e0b23",
   "metadata": {},
   "source": [
    "Сравнение и создание морфологических анализаторов в NLTK.   https://habr.com/ru/post/340404/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1822705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('brown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f250d",
   "metadata": {},
   "source": [
    "**Brown Corpus**  \n",
    "The Brown University Standard Corpus of Present-Day American English (or just Brown Corpus) is an electronic collection of text samples of American English, the first major structured corpus of varied genres. This corpus first set the bar for the scientific study of the frequency and distribution of word categories in everyday language use.\n",
    "\n",
    "\n",
    "https://en.wikipedia.org/wiki/Brown_Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcd2f007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')], [('The', 'AT'), ('jury', 'NN'), ('further', 'RBR'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'NN'), ('presentments', 'NNS'), ('that', 'CS'), ('the', 'AT'), ('City', 'NN-TL'), ('Executive', 'JJ-TL'), ('Committee', 'NN-TL'), (',', ','), ('which', 'WDT'), ('had', 'HVD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'AT'), ('election', 'NN'), (',', ','), ('``', '``'), ('deserves', 'VBZ'), ('the', 'AT'), ('praise', 'NN'), ('and', 'CC'), ('thanks', 'NNS'), ('of', 'IN'), ('the', 'AT'), ('City', 'NN-TL'), ('of', 'IN-TL'), ('Atlanta', 'NP-TL'), (\"''\", \"''\"), ('for', 'IN'), ('the', 'AT'), ('manner', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('the', 'AT'), ('election', 'NN'), ('was', 'BEDZ'), ('conducted', 'VBN'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.brown.tagged_sents(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e1a497b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4160"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_count = int(len(nltk.corpus.brown.tagged_sents(categories='news')) * .9)\n",
    "training_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4de3875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# учебные размеченные данные\n",
    "training_sents = nltk.corpus.brown.tagged_sents(categories='news')[:training_count]\n",
    "\n",
    "# тестовые размеченные данные\n",
    "testing_sents = nltk.corpus.brown.tagged_sents(categories='news')[training_count+1:]\n",
    "\n",
    "# тестовые НЕразмеченные данные\n",
    "testing_sents_notags = nltk.corpus.brown.sents(categories='news')[training_count+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f68cbe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NN'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# самый часто используемый тег - NN(noun, имя существительное) \n",
    "tags = [tag for (word, tag) in \n",
    "        nltk.corpus.brown.tagged_words(categories='news')]\n",
    "nltk.FreqDist(tags).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d14fae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd466e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Holmes', 'NN'),\n",
       " ('went', 'NN'),\n",
       " ('to', 'NN'),\n",
       " (\"Atlanta's\", 'NN'),\n",
       " ('Morehouse', 'NN'),\n",
       " ('(', 'NN'),\n",
       " ('Negro', 'NN'),\n",
       " (')', 'NN'),\n",
       " ('College', 'NN'),\n",
       " (',', 'NN'),\n",
       " ('where', 'NN'),\n",
       " ('he', 'NN'),\n",
       " ('is', 'NN'),\n",
       " ('a', 'NN'),\n",
       " ('B', 'NN'),\n",
       " ('student', 'NN'),\n",
       " ('and', 'NN'),\n",
       " ('star', 'NN'),\n",
       " ('halfback', 'NN'),\n",
       " ('.', 'NN')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# примитивный (вырожденный) тагер - всем присваивает один таг\n",
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "default_tagger.tag(testing_sents_notags[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "988025fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12639776357827476"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# доля правильных тагов\n",
    "default_tagger.accuracy(testing_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1881c4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a4ac5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Holmes', 'VBZ'),\n",
       " ('went', 'NN'),\n",
       " ('to', 'NN'),\n",
       " (\"Atlanta's\", 'NN$'),\n",
       " ('Morehouse', 'NN'),\n",
       " ('(', 'NN'),\n",
       " ('Negro', 'NN'),\n",
       " (')', 'NN'),\n",
       " ('College', 'NN'),\n",
       " (',', 'NN'),\n",
       " ('where', 'NN'),\n",
       " ('he', 'NN'),\n",
       " ('is', 'NNS'),\n",
       " ('a', 'NN'),\n",
       " ('B', 'NN'),\n",
       " ('student', 'NN'),\n",
       " ('and', 'NN'),\n",
       " ('star', 'NN'),\n",
       " ('halfback', 'NN'),\n",
       " ('.', 'NN')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# тагер на простых правилах\n",
    "patterns = [\n",
    "     (r'.*ing$', 'VBG'),               # gerunds\n",
    "     (r'.*ed$', 'VBD'),                # simple past\n",
    "     (r'.*es$', 'VBZ'),                # 3rd singular present\n",
    "     (r'.*ould$', 'MD'),               # modals\n",
    "     (r'.*\\'s$', 'NN$'),               # possessive nouns\n",
    "     (r'.*s$', 'NNS'),                 # plural nouns\n",
    "     (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
    "     (r'.*', 'NN')                     # nouns (default)\n",
    "]\n",
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "regexp_tagger.tag(testing_sents_notags[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5af1a993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20467252396166133"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# доля правильных тагов\n",
    "regexp_tagger.accuracy(testing_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930265ed",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bce857c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Holmes', 'NN'),\n",
       " ('went', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " (\"Atlanta's\", 'NP$'),\n",
       " ('Morehouse', 'NN'),\n",
       " ('(', '('),\n",
       " ('Negro', 'NP'),\n",
       " (')', ')'),\n",
       " ('College', 'NN-TL'),\n",
       " (',', ','),\n",
       " ('where', 'WRB'),\n",
       " ('he', 'PPS'),\n",
       " ('is', 'BEZ'),\n",
       " ('a', 'AT'),\n",
       " ('B', 'NN'),\n",
       " ('student', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('star', 'NN'),\n",
       " ('halfback', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# комбинации из разных тагеров (backoff)\n",
    "\n",
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "unigram_tagger = nltk.UnigramTagger(training_sents, \n",
    "                                    backoff=default_tagger)\n",
    "bigram_tagger = nltk.BigramTagger(training_sents,\n",
    "                                  backoff=unigram_tagger)\n",
    "\n",
    "bigram_tagger.tag(testing_sents_notags[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24068ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8452476038338658"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tagger.accuracy(testing_sents) # доля правильных тагов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40df3f4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9821a709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b1741c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger/averaged_perceptron_tagger.pickle\u001b[0m\n\n  Searched in:\n    - '/home/mechanoid/nltk_data'\n    - '/opt/python3.8/nltk_data'\n    - '/opt/python3.8/share/nltk_data'\n    - '/opt/python3.8/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mToday morning, Arthur felt very good.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# предобученный тагер (английский)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meng\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/python3.8/lib/python3.8/site-packages/nltk/tag/__init__.py:165\u001b[0m, in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpos_tag\u001b[39m(tokens, tagset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m    Use NLTK's currently recommended part of speech tagger to\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m    tag the given list of tokens.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    :rtype: list(tuple(str, str))\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m \u001b[43m_get_tagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pos_tag(tokens, tagset, tagger, lang)\n",
      "File \u001b[0;32m/opt/python3.8/lib/python3.8/site-packages/nltk/tag/__init__.py:107\u001b[0m, in \u001b[0;36m_get_tagger\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m    105\u001b[0m     tagger\u001b[38;5;241m.\u001b[39mload(ap_russian_model_loc)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m \u001b[43mPerceptronTagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tagger\n",
      "File \u001b[0;32m/opt/python3.8/lib/python3.8/site-packages/nltk/tag/perceptron.py:167\u001b[0m, in \u001b[0;36mPerceptronTagger.__init__\u001b[0;34m(self, load)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load:\n\u001b[1;32m    166\u001b[0m     AP_MODEL_LOC \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\n\u001b[0;32m--> 167\u001b[0m         \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtaggers/averaged_perceptron_tagger/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mPICKLE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload(AP_MODEL_LOC)\n",
      "File \u001b[0;32m/opt/python3.8/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger/averaged_perceptron_tagger.pickle\u001b[0m\n\n  Searched in:\n    - '/home/mechanoid/nltk_data'\n    - '/opt/python3.8/nltk_data'\n    - '/opt/python3.8/share/nltk_data'\n    - '/opt/python3.8/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Today morning, Arthur felt very good.'\n",
    "\n",
    "# предобученный тагер (английский)\n",
    "nltk.pos_tag(  nltk.word_tokenize(sentence), lang='eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fda02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Кроме того, иногда одно и то же слово может иметь несколько разных лемм.'\n",
    "# предобученный тагер (русский)\n",
    "nltk.pos_tag(  nltk.word_tokenize(sentence), lang='rus')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879ef894",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a6fafeb4",
   "metadata": {},
   "source": [
    "CC Coordinating Conjunction\n",
    "CD Cardinal Digit\n",
    "DT Determiner\n",
    "EX Existential There. Example: “there is” … think of it like “there exists”)\n",
    "FW Foreign Word.\n",
    "IN Preposition/Subordinating Conjunction.\n",
    "JJ Adjective.\n",
    "JJR Adjective, Comparative.\n",
    "JJS Adjective, Superlative.\n",
    "LS List Marker 1.\n",
    "MD Modal.\n",
    "NN Noun, Singular.\n",
    "NNS Noun Plural.\n",
    "NNP Proper Noun, Singular.\n",
    "NNPS Proper Noun, Plural.\n",
    "PDT Predeterminer.\n",
    "POS Possessive Ending. Example: parent’s\n",
    "PRP Personal Pronoun. Examples: I, he, she\n",
    "PRP$ Possessive Pronoun. Examples: my, his, hers\n",
    "RB Adverb. Examples: very, silently,\n",
    "RBR Adverb, Comparative. Example: better\n",
    "RBS Adverb, Superlative. Example: best\n",
    "RP Particle. Example: give up\n",
    "TO to. Example: go ‘to’ the store.\n",
    "UH Interjection. Example: errrrrrrrm\n",
    "VB Verb, Base Form. Example: take\n",
    "VBD Verb, Past Tense. Example: took\n",
    "VBG Verb, Gerund/Present Participle. Example: taking\n",
    "VBN Verb, Past Participle. Example: taken\n",
    "VBP Verb, Sing Present, non-3d take\n",
    "VBZ Verb, 3rd person sing. present takes\n",
    "WDT wh-determiner. Example: which\n",
    "WP wh-pronoun. Example: who, what\n",
    "WP$ possessive wh-pronoun. Example: whose\n",
    "WRB wh-abverb. Example: where, when"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
