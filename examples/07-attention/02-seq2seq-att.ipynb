{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sequence to Sequence for Neural Machne Translation.__\n",
    "\n",
    "*This notebook is based on [open-source implementation](https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb) of seq2seq NMT in PyTorch.*\n",
    "\n",
    "We are going to implement the model from the [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215) paper. \n",
    "\n",
    "The model will be trained for German to English translations, but it can be applied to any problem that involves going from one sequence to another, such as summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import math\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# from IPython.display import clear_output\n",
    "\n",
    "import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field\n",
    "from torchtext.data import BucketIterator\n",
    "\n",
    "from torchtext.data import Example\n",
    "from torchtext.data import TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>trg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224864</th>\n",
       "      <td>Tom didn't come home that night.</td>\n",
       "      <td>Том в ту ночь не пришёл домой.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10559</th>\n",
       "      <td>Suit yourself.</td>\n",
       "      <td>Воля твоя.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309454</th>\n",
       "      <td>If it were not for the sun, we would all die.</td>\n",
       "      <td>Если б не солнце, мы бы все умерли.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  src  \\\n",
       "224864               Tom didn't come home that night.   \n",
       "10559                                  Suit yourself.   \n",
       "309454  If it were not for the sun, we would all die.   \n",
       "\n",
       "                                        trg  \n",
       "224864       Том в ту ночь не пришёл домой.  \n",
       "10559                            Воля твоя.  \n",
       "309454  Если б не солнце, мы бы все умерли.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# список фраз на английском с переводом на русский\n",
    "with gzip.open('../data/rus-eng/rus.txt.gz', 'rt', encoding='utf-8') as f:\n",
    "    data = f.read().split('\\n')\n",
    "print(len(data))\n",
    "data = pd.DataFrame([ s.split('\\t') for s in data ],columns=['src','trg'])\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ограничиваем набор данных для ускорения процесса\n",
    "data = data.sample(50000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('tmp/data_train.csv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем пакет Torch\n",
    "SEED = 8432\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# создаём препроцессор для текстов\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "spacy_ru = spacy.load('ru_core_news_sm')\n",
    "\n",
    "def tokenize_en(text): return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "def tokenize_ru(text): return [tok.text for tok in spacy_ru.tokenizer(text)]\n",
    "\n",
    "SRC = Field(tokenize = tokenize_en, init_token = '<sos>', eos_token = '<eos>', lower = True)\n",
    "TRG = Field(tokenize = tokenize_ru, init_token = '<sos>', eos_token = '<eos>', lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/usr/lib/python3.9/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# загружаем датасет в формате Torch\n",
    "# и выполняем предобработку данных\n",
    "fields = [('src',SRC),('trg',TRG)]\n",
    "(train_data,) = TabularDataset.splits(\n",
    "                            path = 'tmp',\n",
    "                            train = 'data_train.csv',\n",
    "                            format = 'tsv', #'tsv' for tabs, 'csv' for commas\n",
    "                            fields = fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50001"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# количество примеров\n",
    "len(train_data.examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# словари \n",
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# раскидываем данные по батчам,\n",
    "# в один батч будут помещены тексты одинаковой (или близкой) длинны\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "(train_iterator,) = BucketIterator.splits(\n",
    "    (train_data,), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # пример батча\n",
    "# for x in train_iterator:  break\n",
    "# print(x)\n",
    "# print(x.src.shape, x.trg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## строим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, n_layers, dropout=dropout, bidirectional=True)\n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "\n",
    "    def forward(self, src_batch):\n",
    "        # src [sent len, batch size]\n",
    "\n",
    "        # [sent len, batch size, emb dim]\n",
    "        embedded = self.embedding(src_batch)\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        # outputs -> [sent len, batch size, hidden dim * n directions]\n",
    "        # hidden -> [n layers * n directions, batch size, hidden dim]\n",
    "\n",
    "        # initial decoder hidden is final hidden state of the forwards and\n",
    "        # backwards encoder RNNs fed through a linear layer\n",
    "        concated = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
    "        hidden = torch.tanh(self.fc(concated))\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "\n",
    "        # enc_hid_dim multiply by 2 due to bidirectional\n",
    "        self.fc1 = nn.Linear(enc_hid_dim * 2 + dec_hid_dim, dec_hid_dim)\n",
    "        self.fc2 = nn.Linear(dec_hid_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, encoder_outputs, hidden):\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        \n",
    "        # repeat encoder hidden state src_len times [batch size, sent len, dec hid dim]\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        # reshape/permute the encoder output, so that the batch size comes first\n",
    "        # [batch size, sent len, enc hid dim * 2], times 2 because of bidirectional\n",
    "        outputs = encoder_outputs.permute(1, 0, 2)\n",
    "\n",
    "        # the attention mechanism receives a concatenation of the hidden state\n",
    "        # and the encoder output\n",
    "        concat = torch.cat((hidden, outputs), dim=2)\n",
    "        \n",
    "        # fully connected layer and softmax layer to compute the attention weight\n",
    "        # [batch size, sent len, dec hid dim]\n",
    "        energy = torch.tanh(self.fc1(concat))\n",
    "\n",
    "        # attention weight should be of [batch size, sent len]\n",
    "        attention = self.fc2(energy).squeeze(dim=2)        \n",
    "        attention_weight = torch.softmax(attention, dim=1)\n",
    "        return attention_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, n_layers,\n",
    "                 dropout, attention):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.attention = attention\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(enc_hid_dim * 2 + emb_dim, dec_hid_dim, n_layers, dropout=dropout)\n",
    "        self.linear = nn.Linear(dec_hid_dim, output_dim)\n",
    "\n",
    "    def forward(self, trg, encoder_outputs, hidden):\n",
    "        # trg [batch size]\n",
    "        # outputs [src sen len, batch size, enc hid dim * 2], times 2 due to bidirectional\n",
    "        # hidden [batch size, dec hid dim]\n",
    "\n",
    "        # [batch size, 1, sent len] \n",
    "        attention = self.attention(encoder_outputs, hidden).unsqueeze(1)\n",
    "\n",
    "        # [batch size, sent len, enc hid dim * 2]\n",
    "        outputs = encoder_outputs.permute(1, 0, 2)\n",
    "\n",
    "        # [1, batch size, enc hid dim * 2]\n",
    "        context = torch.bmm(attention, outputs).permute(1, 0, 2)\n",
    "\n",
    "        # input sentence -> embedding\n",
    "        # [1, batch size, emb dim]\n",
    "        embedded = self.embedding(trg.unsqueeze(0))\n",
    "        rnn_input = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        outputs, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        prediction = self.linear(outputs.squeeze(0))\n",
    "        return prediction, hidden.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src_batch, trg_batch, teacher_forcing_ratio=0.5):\n",
    "        max_len, batch_size = trg_batch.shape\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        # tensor to store decoder's output\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        # encoder_outputs : all hidden states of the input sequence (forward and backward)\n",
    "        # hidden : final forward and backward hidden states, passed through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src_batch)\n",
    "\n",
    "        trg = trg_batch[0]\n",
    "        for i in range(1, max_len):\n",
    "            prediction, hidden = self.decoder(trg, encoder_outputs, hidden)\n",
    "            outputs[i] = prediction\n",
    "\n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                trg = trg_batch[i]\n",
    "            else:\n",
    "                trg = prediction.argmax(1)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjustable parameters\n",
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "N_LAYERS = 1\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(5015, 256)\n",
       "    (rnn): GRU(256, 512, dropout=0.5, bidirectional=True)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (fc1): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(10308, 256)\n",
       "    (rnn): GRU(1280, 512, dropout=0.5)\n",
       "    (linear): Linear(in_features=512, out_features=10308, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, N_LAYERS, DEC_DROPOUT, attention)\n",
    "seq2seq = Seq2Seq(encoder, decoder, device).to(device)\n",
    "seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## процесс обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(seq2seq.parameters())\n",
    "\n",
    "# ignore the padding index when calculating the loss\n",
    "PAD_IDX = TRG.vocab.stoi['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(seq2seq, iterator, optimizer, criterion):\n",
    "    seq2seq.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = seq2seq(batch.src, batch.trg)\n",
    "\n",
    "        # the loss function only works on 2d inputs\n",
    "        # and 1d targets we need to flatten each of them\n",
    "        outputs_flatten = outputs[1:].view(-1, outputs.shape[-1])\n",
    "        trg_flatten = batch.trg[1:].view(-1)\n",
    "        loss = criterion(outputs_flatten, trg_flatten)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\tTrain Loss: 4.325\n",
      "Epoch: 02\tTrain Loss: 2.706\n",
      "Epoch: 03\tTrain Loss: 1.914\n",
      "Epoch: 04\tTrain Loss: 1.438\n",
      "Epoch: 05\tTrain Loss: 1.097\n",
      "Epoch: 06\tTrain Loss: 0.867\n",
      "Epoch: 07\tTrain Loss: 0.694\n",
      "Epoch: 08\tTrain Loss: 0.552\n",
      "Epoch: 09\tTrain Loss: 0.447\n",
      "Epoch: 10\tTrain Loss: 0.370\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "#best_valid_loss = float('inf')\n",
    "train_history=[]\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    # start_time = time.time()\n",
    "    train_loss = train(seq2seq, train_iterator, optimizer, criterion)\n",
    "    train_history.append(train_loss)\n",
    "\n",
    "    # valid_loss = evaluate(seq2seq, valid_iterator, criterion)\n",
    "    # end_time = time.time()\n",
    "    #epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         torch.save(seq2seq.state_dict(), 'tut2-model.pt')\n",
    "\n",
    "#     print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "#     print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "#     print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02}\\tTrain Loss: {train_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb4315235b0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.grid()\n",
    "plt.plot(train_history,label='train loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## проверяем результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, \n",
    "                       src_field, \n",
    "                       trg_field, \n",
    "                       model, \n",
    "                       device, \n",
    "                       max_len=50,\n",
    "                       spacy_lang_mod = 'ru_core_news_sm'\n",
    "                      ):\n",
    "    model.eval()\n",
    "        \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load(spacy_lang_mod)\n",
    "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
    "    src_len = torch.LongTensor([len(src_indexes)]).to(device)\n",
    "    \n",
    "    with torch.no_grad():  \n",
    "        # hidden, cell = model.encoder(src_tensor)\n",
    "        outputs, hidden = model.encoder(src_tensor)\n",
    "        \n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "\n",
    "    for t in range(1, max_len):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        # output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
    "        output, hidden = model.decoder(trg_tensor, outputs, hidden )\n",
    "        \n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]: break\n",
    "    \n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "    \n",
    "    return trg_tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_example_translation():\n",
    "    example_idx = np.random.choice(np.arange(len(train_data)))\n",
    "    src = vars(train_data.examples[example_idx])['src']\n",
    "    trg = vars(train_data.examples[example_idx])['trg']\n",
    "    \n",
    "    translation = translate_sentence(src, SRC, TRG, seq2seq, device)\n",
    "   \n",
    "    return [' '.join(src),' '.join(trg),' '.join(translation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_example_translation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  </th><th>src                                                                                                                                             </th><th>trg                                                                                                        </th><th>pred                                                                                                </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\"> 0</td><td>&quot; you dislike tom , do n&#x27;t you ? &quot; &quot; it &#x27;s not that i dislike like him , it &#x27;s just that i kind of have trouble dealing with people like him . &quot;</td><td>&quot; ты не любишь тома ? &quot; - &quot; не то чтобы не люблю - мне просто немного трудно иметь дело с такими людьми &quot; .</td><td>&quot; ты не любишь тома ? &quot; - &quot; не люблю мне просто немного с с с с людьми с ним людьми с людьми . &lt;eos&gt;</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 1</td><td>would you like a newspaper or magazine ?                                                                                                        </td><td>вам газету или журнал ?                                                                                    </td><td>вам газету или журнал ? &lt;eos&gt;                                                                       </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 2</td><td>tom gets very animated when he &#x27;s watching rugby on tv .                                                                                        </td><td>том очень оживляется , когда смотрит регби по телевизору .                                                 </td><td>том очень &lt;unk&gt; , когда смотрит &lt;unk&gt; по телевизору . &lt;eos&gt;                                         </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 3</td><td>i never lie to you .                                                                                                                            </td><td>я никогда тебе не вру .                                                                                    </td><td>я никогда тебе не вру . &lt;eos&gt;                                                                       </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 4</td><td>tom asked for money .                                                                                                                           </td><td>том просил денег .                                                                                         </td><td>том попросил денег . &lt;eos&gt;                                                                          </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 5</td><td>are you sure tom is going to win ?                                                                                                              </td><td>вы уверены , что том победит ?                                                                             </td><td>ты уверен , что том победит ? &lt;eos&gt;                                                                 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 6</td><td>what time did you see tom ?                                                                                                                     </td><td>в какое время ты видел тома ?                                                                              </td><td>в какое ты видел тома ? &lt;eos&gt;                                                                       </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 7</td><td>you do n&#x27;t have to worry . i &#x27;ll do it myself .                                                                                                 </td><td>можете не беспокоиться . я сам это сделаю .                                                                </td><td>не нужно беспокоиться . я сам это сам . &lt;eos&gt;                                                       </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 8</td><td>tell us who you are .                                                                                                                           </td><td>расскажите нам , кто вы .                                                                                  </td><td>расскажите нам , кто вы . &lt;eos&gt;                                                                     </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 9</td><td>how long will it take to you ?                                                                                                                  </td><td>сколько это у тебя займёт ?                                                                                </td><td>сколько это у тебя займёт ? &lt;eos&gt;                                                                   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">10</td><td>ca n&#x27;t you help us ?                                                                                                                            </td><td>вы не можете нам помочь ?                                                                                  </td><td>ты нам не поможешь ? &lt;eos&gt;                                                                          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">11</td><td>can i go with you ?                                                                                                                             </td><td>можно мне с вами ?                                                                                         </td><td>можно мне поехать с вами ? &lt;eos&gt;                                                                    </td></tr>\n",
       "<tr><td style=\"text-align: right;\">12</td><td>that &#x27;s tom &#x27;s boat .                                                                                                                           </td><td>это лодка тома .                                                                                           </td><td>это лодка тома . &lt;eos&gt;                                                                              </td></tr>\n",
       "<tr><td style=\"text-align: right;\">13</td><td>nobody knew what to say .                                                                                                                       </td><td>никто не знал , что сказать .                                                                              </td><td>никто не знал , что сказать . &lt;eos&gt;                                                                 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">14</td><td>i already knew about this .                                                                                                                     </td><td>я об этом уже знал .                                                                                       </td><td>я об этом уже знал . &lt;eos&gt;                                                                          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">15</td><td>we want to hire you .                                                                                                                           </td><td>мы хотим нанять вас .                                                                                      </td><td>мы хотим нанять вас . &lt;eos&gt;                                                                         </td></tr>\n",
       "<tr><td style=\"text-align: right;\">16</td><td>he can not have said that .                                                                                                                     </td><td>он не мог этого сказать .                                                                                  </td><td>он не мог такого сказать . &lt;eos&gt;                                                                    </td></tr>\n",
       "<tr><td style=\"text-align: right;\">17</td><td>are you sure it &#x27;s all true ?                                                                                                                   </td><td>ты уверен , что это всё правда ?                                                                           </td><td>ты уверен , что это всё правда ? &lt;eos&gt;                                                              </td></tr>\n",
       "<tr><td style=\"text-align: right;\">18</td><td>tom says he left a note .                                                                                                                       </td><td>том говорит , что оставил записку .                                                                        </td><td>том говорит , что оставил записку . &lt;eos&gt;                                                           </td></tr>\n",
       "<tr><td style=\"text-align: right;\">19</td><td>put down your pencil .                                                                                                                          </td><td>положите свой карандаш .                                                                                   </td><td>положи свой карандаш . &lt;eos&gt;                                                                        </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th style=\"text-align: right;\">  </th><th>src                                                                                                                                             </th><th>trg                                                                                                        </th><th>pred                                                                                                </th></tr>\\n</thead>\\n<tbody>\\n<tr><td style=\"text-align: right;\"> 0</td><td>&quot; you dislike tom , do n&#x27;t you ? &quot; &quot; it &#x27;s not that i dislike like him , it &#x27;s just that i kind of have trouble dealing with people like him . &quot;</td><td>&quot; ты не любишь тома ? &quot; - &quot; не то чтобы не люблю - мне просто немного трудно иметь дело с такими людьми &quot; .</td><td>&quot; ты не любишь тома ? &quot; - &quot; не люблю мне просто немного с с с с людьми с ним людьми с людьми . &lt;eos&gt;</td></tr>\\n<tr><td style=\"text-align: right;\"> 1</td><td>would you like a newspaper or magazine ?                                                                                                        </td><td>вам газету или журнал ?                                                                                    </td><td>вам газету или журнал ? &lt;eos&gt;                                                                       </td></tr>\\n<tr><td style=\"text-align: right;\"> 2</td><td>tom gets very animated when he &#x27;s watching rugby on tv .                                                                                        </td><td>том очень оживляется , когда смотрит регби по телевизору .                                                 </td><td>том очень &lt;unk&gt; , когда смотрит &lt;unk&gt; по телевизору . &lt;eos&gt;                                         </td></tr>\\n<tr><td style=\"text-align: right;\"> 3</td><td>i never lie to you .                                                                                                                            </td><td>я никогда тебе не вру .                                                                                    </td><td>я никогда тебе не вру . &lt;eos&gt;                                                                       </td></tr>\\n<tr><td style=\"text-align: right;\"> 4</td><td>tom asked for money .                                                                                                                           </td><td>том просил денег .                                                                                         </td><td>том попросил денег . &lt;eos&gt;                                                                          </td></tr>\\n<tr><td style=\"text-align: right;\"> 5</td><td>are you sure tom is going to win ?                                                                                                              </td><td>вы уверены , что том победит ?                                                                             </td><td>ты уверен , что том победит ? &lt;eos&gt;                                                                 </td></tr>\\n<tr><td style=\"text-align: right;\"> 6</td><td>what time did you see tom ?                                                                                                                     </td><td>в какое время ты видел тома ?                                                                              </td><td>в какое ты видел тома ? &lt;eos&gt;                                                                       </td></tr>\\n<tr><td style=\"text-align: right;\"> 7</td><td>you do n&#x27;t have to worry . i &#x27;ll do it myself .                                                                                                 </td><td>можете не беспокоиться . я сам это сделаю .                                                                </td><td>не нужно беспокоиться . я сам это сам . &lt;eos&gt;                                                       </td></tr>\\n<tr><td style=\"text-align: right;\"> 8</td><td>tell us who you are .                                                                                                                           </td><td>расскажите нам , кто вы .                                                                                  </td><td>расскажите нам , кто вы . &lt;eos&gt;                                                                     </td></tr>\\n<tr><td style=\"text-align: right;\"> 9</td><td>how long will it take to you ?                                                                                                                  </td><td>сколько это у тебя займёт ?                                                                                </td><td>сколько это у тебя займёт ? &lt;eos&gt;                                                                   </td></tr>\\n<tr><td style=\"text-align: right;\">10</td><td>ca n&#x27;t you help us ?                                                                                                                            </td><td>вы не можете нам помочь ?                                                                                  </td><td>ты нам не поможешь ? &lt;eos&gt;                                                                          </td></tr>\\n<tr><td style=\"text-align: right;\">11</td><td>can i go with you ?                                                                                                                             </td><td>можно мне с вами ?                                                                                         </td><td>можно мне поехать с вами ? &lt;eos&gt;                                                                    </td></tr>\\n<tr><td style=\"text-align: right;\">12</td><td>that &#x27;s tom &#x27;s boat .                                                                                                                           </td><td>это лодка тома .                                                                                           </td><td>это лодка тома . &lt;eos&gt;                                                                              </td></tr>\\n<tr><td style=\"text-align: right;\">13</td><td>nobody knew what to say .                                                                                                                       </td><td>никто не знал , что сказать .                                                                              </td><td>никто не знал , что сказать . &lt;eos&gt;                                                                 </td></tr>\\n<tr><td style=\"text-align: right;\">14</td><td>i already knew about this .                                                                                                                     </td><td>я об этом уже знал .                                                                                       </td><td>я об этом уже знал . &lt;eos&gt;                                                                          </td></tr>\\n<tr><td style=\"text-align: right;\">15</td><td>we want to hire you .                                                                                                                           </td><td>мы хотим нанять вас .                                                                                      </td><td>мы хотим нанять вас . &lt;eos&gt;                                                                         </td></tr>\\n<tr><td style=\"text-align: right;\">16</td><td>he can not have said that .                                                                                                                     </td><td>он не мог этого сказать .                                                                                  </td><td>он не мог такого сказать . &lt;eos&gt;                                                                    </td></tr>\\n<tr><td style=\"text-align: right;\">17</td><td>are you sure it &#x27;s all true ?                                                                                                                   </td><td>ты уверен , что это всё правда ?                                                                           </td><td>ты уверен , что это всё правда ? &lt;eos&gt;                                                              </td></tr>\\n<tr><td style=\"text-align: right;\">18</td><td>tom says he left a note .                                                                                                                       </td><td>том говорит , что оставил записку .                                                                        </td><td>том говорит , что оставил записку . &lt;eos&gt;                                                           </td></tr>\\n<tr><td style=\"text-align: right;\">19</td><td>put down your pencil .                                                                                                                          </td><td>положите свой карандаш .                                                                                   </td><td>положи свой карандаш . &lt;eos&gt;                                                                        </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tabulate import tabulate \n",
    "\n",
    "tabulate(\n",
    "    [ get_example_translation() for i in range(20) ], \n",
    "    headers=['src', 'trg', 'pred'], \n",
    "    tablefmt='html', \n",
    "    showindex='always'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # инициализация модели\n",
    "# def init_weights(m): \n",
    "#     for p in m.parameters():\n",
    "#         nn.init.uniform_(p,-.08,.08)\n",
    "            \n",
    "# model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # метод оптимизации\n",
    "# optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # функция потери\n",
    "# PAD_IDX = TRG.vocab.stoi['<pad>']\n",
    "# criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # процедура обучения\n",
    "# def train(model, \n",
    "#           iterator, \n",
    "#           optimizer, \n",
    "#           criterion, \n",
    "#           clip, \n",
    "#           train_history=None, \n",
    "#           ):\n",
    "    \n",
    "#     model.train()\n",
    "    \n",
    "#     epoch_loss = 0\n",
    "#     history = []\n",
    "#     for i, batch in enumerate(iterator):\n",
    "        \n",
    "#         src = batch.src\n",
    "#         trg = batch.trg\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(src, trg)\n",
    "        \n",
    "#         output = output[1:].view(-1, output.shape[-1])\n",
    "#         trg = trg[1:].view(-1)\n",
    "        \n",
    "#         loss = criterion(output, trg)\n",
    "#         loss.backward()\n",
    "        \n",
    "#         # clip the gradient\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "#         optimizer.step()\n",
    "        \n",
    "#         epoch_loss += loss.item()\n",
    "        \n",
    "#         history.append(loss.cpu().data.numpy())\n",
    "                      \n",
    "#     return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# N_EPOCHS = 20\n",
    "# CLIP = 1\n",
    "\n",
    "# for epoch in range(N_EPOCHS):\n",
    "    \n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     train_loss = train(model, \n",
    "#                        train_iterator, \n",
    "#                        optimizer, \n",
    "#                        criterion, \n",
    "#                        CLIP, \n",
    "#                        train_history, \n",
    "#                       )\n",
    "       \n",
    "#     train_history.append(train_loss)\n",
    "\n",
    "#     print(f'Epoch: {epoch+1:02}\\tTrain Loss: {train_loss:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
