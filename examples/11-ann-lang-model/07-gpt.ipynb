{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd386f23",
   "metadata": {},
   "source": [
    "__Нейросетевая языковая модель GPT__ \n",
    "\n",
    "Евгений Борисов <esborisov@sevsu.ru>\n",
    "\n",
    "генератор текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982a1147",
   "metadata": {},
   "source": [
    "https://github.com/sberbank-ai/ru-gpts\n",
    "\n",
    "https://pythonrepo.com/repo/sberbank-ai-ru-gpts-python-natural-language-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de39520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Нахмурилась : - Мои ...',\n",
       " 'Понимающе глянул на черных девчонок',\n",
       " 'Как и любое другое место',\n",
       " '-- Но ведь я нахожусь',\n",
       " '- и , обжуливая очередь',\n",
       " 'Над сонной стоянкой пронеслось движение',\n",
       " 'Дородная фигура с трудом выбиралась',\n",
       " 'Запомни : черного пассажира не',\n",
       " 'Варенья немножко скушал , чаю',\n",
       " 'Сметливый Шмуэль был непререкаемым авторитетом',\n",
       " 'Из нее под дождь вышел',\n",
       " 'Я везу его прочь от',\n",
       " 'Из разодранного пакета вываливались ломти',\n",
       " 'Я знаю уже почти всех',\n",
       " 'Ну , как разозлится судья',\n",
       " 'Три спальни , веранда ,',\n",
       " 'Меня не учили плавать :',\n",
       " '- Если вынесут `` Кеннеди',\n",
       " 'Я развил скорость , обогнал',\n",
       " 'Он с поклоном о чем-то',\n",
       " '- По-моему , мы совсем',\n",
       " 'Но Фрэнк отрицательно покачал головой',\n",
       " '- А вы подумайте :',\n",
       " 'Я хотел сказать сыну ,',\n",
       " 'Один схватил пачку размокших сигарет']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "from random import sample\n",
    "from nltk.tokenize import sent_tokenize as nltk_sentence_split\n",
    "from nltk.tokenize import word_tokenize as nltk_tokenize_word\n",
    "\n",
    "file_name = '../data/lobas-taxisty.txt.gz'\n",
    "\n",
    "n_samples = 25 # количество начальных фраз\n",
    "min_sentence_len = 10 # минимальный размер предложения в токенах\n",
    "init_seq_len = 5 # размер начальной последовательности \n",
    "\n",
    "assert min_sentence_len>init_seq_len\n",
    "\n",
    "with gzip.open(file_name,'rt',encoding='utf-8') as f: text = f.read()\n",
    "    \n",
    "text = [ \n",
    "        nltk_tokenize_word(s,language='russian') # разбиваем предложения на слова\n",
    "        for s in nltk_sentence_split(text,language='russian') # режем текст на отдельные предложения\n",
    "    ]\n",
    "\n",
    "text = [ sentence for sentence in text if len(sentence)>min_sentence_len ] \n",
    "\n",
    "text = [ ' '.join(sentence[:init_seq_len]) for sentence in sample(text,n_samples) ]\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f581fb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bb84b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3261e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~1GB\n",
    "\n",
    "# https://huggingface.co/sberbank-ai\n",
    "\n",
    "# Git Large File Storage\n",
    "# !pacman -Ss git-lfs\n",
    "\n",
    "# !git clone https://huggingface.co/sberbank-ai/rugpt3small_based_on_gpt2\n",
    "\n",
    "# !cd rugpt3small_based_on_gpt2 && git lfs install\n",
    "# !cd rugpt3small_based_on_gpt2 && git lfs pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9998a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"sberbank-ai/rugpt3small_based_on_gpt2\"\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name_or_path).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4dc3b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4aeb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence = \"Александр Сергеевич Пушкин родился в\"\n",
    "# sentence = \"Его отец был крепостным крестьянином, а мать\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "346676ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "init> Нахмурилась : - Мои ...\n",
      "gpt>  А ты что, не знаешь, что я - это\n",
      "------------------------------\n",
      "\n",
      "init> Понимающе глянул на черных девчонок\n",
      "gpt> , которые, как и он, были одеты в одинаковые костюмы.\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "init> Как и любое другое место\n",
      "gpt> , где можно найти что-то интересное, нужно обязательно посетить.  В\n",
      "------------------------------\n",
      "\n",
      "init> -- Но ведь я нахожусь\n",
      "gpt>  в другом мире, в другом мире, в другом мире.  Я не\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "init> - и , обжуливая очередь\n",
      "gpt>  не пропускает ни одного клиента.  В итоге, клиент\n",
      "------------------------------\n",
      "\n",
      "init> Над сонной стоянкой пронеслось движение\n",
      "gpt> .\n",
      "------------------------------\n",
      "\n",
      "init> Дородная фигура с трудом выбиралась\n",
      "gpt>  из-под одеяла.\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "init> Запомни : черного пассажира не\n",
      "gpt>  бывает.\n",
      "------------------------------\n",
      "\n",
      "init> Варенья немножко скушал , чаю\n",
      "gpt> попил, а потом в постельку и спать.\n",
      "------------------------------\n",
      "\n",
      "init> Сметливый Шмуэль был непререкаемым авторитетом\n",
      "gpt>  в области строительства.  Он был одним\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "init> Из нее под дождь вышел\n",
      "gpt>  и я.\n",
      "------------------------------\n",
      "\n",
      "init> Я везу его прочь от\n",
      "gpt>  дома, — сказал он. — Я не хочу, чтобы\n",
      "------------------------------\n",
      "\n",
      "init> Из разодранного пакета вываливались ломти\n",
      "gpt>  мяса, куски мяса, куски мяса, куски мяса\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "init> Я знаю уже почти всех\n",
      "gpt> , кто был в этом зале.\n",
      "------------------------------\n",
      "\n",
      "init> Ну , как разозлится судья\n",
      "gpt>  если я не буду отвечать на его вопросы?\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "init> Три спальни , веранда ,\n",
      "gpt> ерраса, бассейн, сауна, джакузи, хамам\n",
      "------------------------------\n",
      "\n",
      "init> Меня не учили плавать :\n",
      "gpt> (\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "init> - Если вынесут `` Кеннеди\n",
      "gpt> , то `` Кеннеди `` будет `\n",
      "------------------------------\n",
      "\n",
      "init> Я развил скорость , обогнал\n",
      "gpt> машину и стал ждать.  Через несколько минут он уже был на\n",
      "------------------------------\n",
      "\n",
      "init> Он с поклоном о чем-то\n",
      "gpt>  спросил у меня.\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "init> - По-моему , мы совсем\n",
      "gpt> не похожи на тех, кто живет в России.  Я не\n",
      "------------------------------\n",
      "\n",
      "init> Но Фрэнк отрицательно покачал головой\n",
      "gpt> .\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "init> - А вы подумайте :\n",
      "gpt> -)\n",
      "------------------------------\n",
      "\n",
      "init> Я хотел сказать сыну ,\n",
      "gpt> что он не может быть отцом, потому что он не может быть отцом.\n",
      "------------------------------\n",
      "\n",
      "init> Один схватил пачку размокших сигарет\n",
      "gpt>  и швырнул ее в окно.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for sentence in text:\n",
    "    input_ids = tokenizer.encode(sentence, return_tensors='pt').cuda()\n",
    "    out = model.generate(input_ids.cuda())\n",
    "    generated_text = list(map(tokenizer.decode, out))[0].split('\\n')[0]\n",
    "    \n",
    "    print('\\n'+'init> '+sentence)\n",
    "    print('gpt> '+generated_text[len(sentence):])\n",
    "    print('-'*30)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7254a6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
