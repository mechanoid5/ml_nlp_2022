{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd28d18a",
   "metadata": {},
   "source": [
    "__Нейросетевая языковая модель на основе LSTM__ \n",
    "\n",
    "Евгений Борисов <esborisov@sevsu.ru>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caa80a7",
   "metadata": {},
   "source": [
    "Shivam Bansal   \n",
    "Language Modelling and Text Generation using LSTMs — Deep Learning for NLP.    \n",
    "Mar 26, 2018\n",
    "\n",
    "https://medium.com/@shivambansal36/language-modelling-text-generation-using-lstms-deep-learning-for-nlp-ed36b224b275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a54cf991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "# from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "# from keras.callbacks import EarlyStopping\n",
    "# from keras.models import Sequential\n",
    "# import keras.utils as ku \n",
    "# import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97506365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465595\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "FILE_DATA = '../data/dostoevsky-besy-p2.txt.gz'\n",
    "with gzip.open(FILE_DATA,'rt',encoding='utf-8') as f: data = f.read()     \n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b39cc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Tokenizer: Text tokenization utility class.\n",
    "# Functions\n",
    "# hashing_trick(...): Converts a text to a sequence of indexes in a fixed-size hashing space.\n",
    "# one_hot(...): One-hot encodes a text into a list of word indexes of size n.\n",
    "# text_to_word_sequence(...): Converts a text to a sequence of words (or tokens).\n",
    "# tokenizer_from_json(...): Parses a JSON tokenizer configuration file and returns a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41c3159a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Что, вы улыбнулись?',\n",
       " 'Вы никого не оскорбляете, и вас все ненавидят; вы смотрите всем ровней, и вас все боятся, это хорошо.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import sample\n",
    "from nltk.tokenize import sent_tokenize as nltk_sentence_split\n",
    "# from nltk.tokenize import word_tokenize as nltk_tokenize_word\n",
    "\n",
    "# text = [ \n",
    "#     nltk_tokenize_word(s) # разбиваем предложения на слова\n",
    "#     for s in nltk_sentence_split(text) # режем текст на отдельные предложения\n",
    "# ]\n",
    "# print('предложений: %i\\n'%(len(text)))\n",
    "\n",
    "text = nltk_sentence_split(data)\n",
    "\n",
    "sample(text,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65c46cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text.StateBasedSentenceBreaker \n",
    "# break_sentences(\n",
    "#     doc\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87d7451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow\n",
    "# tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3492638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# # class Tokenizer: Text tokenization utility class.\n",
    "# # Functions\n",
    "# # hashing_trick(...): Converts a text to a sequence of indexes in a fixed-size hashing space.\n",
    "# # one_hot(...): One-hot encodes a text into a list of word indexes of size n.\n",
    "# # text_to_word_sequence(...): Converts a text to a sequence of words (or tokens).\n",
    "# # tokenizer_from_json(...): Parses a JSON tokenizer configuration file and returns a\n",
    "\n",
    "# tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af80aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "209f02c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2ce6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# line = text[1]\n",
    "# tokenizer.texts_to_sequences([line])[0]\n",
    "\n",
    "\n",
    "# token_list[:i+1]\n",
    "# for line in text\n",
    "# for i,token_idx in enumerate( tokenizer.texts_to_sequences([line])[0] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5976b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_sequences = []\n",
    "# for line in text:\n",
    "#     token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "#     for i in range(1, len(token_list)):\n",
    "#         n_gram_sequence = token_list[:i+1]\n",
    "#         input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e23d45f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# max_sequence_len = max([len(x) for x in input_sequences])\n",
    "# input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "# # input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffd28fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    " # create predictors and label\n",
    "# predictors, label = input_sequences[:,:-1],input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5caa9002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras.utils as ku \n",
    "# label = ku.np_utils.to_categorical(label, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e63aa7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_preparation(data):\n",
    "    # basic cleanup\n",
    "    corpus = text = nltk_sentence_split(data)\n",
    "    \n",
    "    # data.lower().split(\"\\n\")\n",
    "\n",
    "    # tokenization\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "    # create input sequences using list of tokens\n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "\n",
    "    # pad sequences \n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "    # create predictors and label\n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.np_utils.to_categorical(label, num_classes=total_words)\n",
    "\n",
    "    return predictors, label, max_sequence_len, total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34bda208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_preparation(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e61067d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "# import keras.utils as ku \n",
    "# import numpy as np \n",
    "\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54405a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(predictors, label, max_sequence_len, total_words):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(total_words, 10, input_length=max_sequence_len-1))\n",
    "    model.add(LSTM(150, return_sequences = True))\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "    model.fit(predictors, label, epochs=100, verbose=1, callbacks=[earlystop])\n",
    "    print( model.summary() )\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d277f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = model.predict_classes(token_list, verbose=0)\n",
    "\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12902942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465595\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "FILE_DATA = '../data/dostoevsky-besy-p2.txt.gz'\n",
    "with gzip.open(FILE_DATA,'rt',encoding='utf-8') as f: data = f.read()     \n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8e7537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 14:07:05.598204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-22 14:07:05.798047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-22 14:07:05.798235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-22 14:07:05.799202: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-22 14:07:05.799619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-22 14:07:05.799805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-22 14:07:05.799945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-22 14:07:06.150317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-22 14:07:06.150495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-22 14:07:06.150623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-22 14:07:06.150731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4904 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2022-03-22 14:07:06.574013: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4171989300 exceeds 10% of free system memory.\n",
      "2022-03-22 14:07:09.185991: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4171989300 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 14:07:14.071789: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2104/2108 [============================>.] - ETA: 0s - loss: 8.0136 - accuracy: 0.0421WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 34s 14ms/step - loss: 8.0135 - accuracy: 0.0421\n",
      "Epoch 2/100\n",
      "2106/2108 [============================>.] - ETA: 0s - loss: 7.5215 - accuracy: 0.0448WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 7.5218 - accuracy: 0.0448\n",
      "Epoch 3/100\n",
      "2108/2108 [==============================] - ETA: 0s - loss: 7.3071 - accuracy: 0.0506WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 7.3071 - accuracy: 0.0506\n",
      "Epoch 4/100\n",
      "2106/2108 [============================>.] - ETA: 0s - loss: 7.0949 - accuracy: 0.0564WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 7.0950 - accuracy: 0.0564\n",
      "Epoch 5/100\n",
      "2105/2108 [============================>.] - ETA: 0s - loss: 6.8837 - accuracy: 0.0620WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 6.8832 - accuracy: 0.0621\n",
      "Epoch 6/100\n",
      "2105/2108 [============================>.] - ETA: 0s - loss: 6.6830 - accuracy: 0.0682WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 6.6831 - accuracy: 0.0681\n",
      "Epoch 7/100\n",
      "2107/2108 [============================>.] - ETA: 0s - loss: 6.4893 - accuracy: 0.0739WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 6.4893 - accuracy: 0.0739\n",
      "Epoch 8/100\n",
      "2108/2108 [==============================] - ETA: 0s - loss: 6.2848 - accuracy: 0.0791WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 6.2848 - accuracy: 0.0791\n",
      "Epoch 9/100\n",
      "2107/2108 [============================>.] - ETA: 0s - loss: 6.0778 - accuracy: 0.0865WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 6.0777 - accuracy: 0.0865\n",
      "Epoch 10/100\n",
      "2106/2108 [============================>.] - ETA: 0s - loss: 5.8769 - accuracy: 0.0922WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 5.8772 - accuracy: 0.0922\n",
      "Epoch 11/100\n",
      "2104/2108 [============================>.] - ETA: 0s - loss: 5.6818 - accuracy: 0.0987WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 5.6819 - accuracy: 0.0987\n",
      "Epoch 12/100\n",
      "2106/2108 [============================>.] - ETA: 0s - loss: 5.4886 - accuracy: 0.1047WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 5.4885 - accuracy: 0.1047\n",
      "Epoch 13/100\n",
      "2105/2108 [============================>.] - ETA: 0s - loss: 5.3027 - accuracy: 0.1110WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 5.3030 - accuracy: 0.1109\n",
      "Epoch 14/100\n",
      "2104/2108 [============================>.] - ETA: 0s - loss: 5.1244 - accuracy: 0.1174WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 5.1249 - accuracy: 0.1173\n",
      "Epoch 15/100\n",
      "2108/2108 [==============================] - ETA: 0s - loss: 4.9544 - accuracy: 0.1245WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 4.9544 - accuracy: 0.1245\n",
      "Epoch 16/100\n",
      "2106/2108 [============================>.] - ETA: 0s - loss: 4.7909 - accuracy: 0.1348WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 4.7908 - accuracy: 0.1348\n",
      "Epoch 17/100\n",
      "2107/2108 [============================>.] - ETA: 0s - loss: 4.6351 - accuracy: 0.1474WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 4.6352 - accuracy: 0.1474\n",
      "Epoch 18/100\n",
      "2106/2108 [============================>.] - ETA: 0s - loss: 4.4874 - accuracy: 0.1630WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 4.4876 - accuracy: 0.1630\n",
      "Epoch 19/100\n",
      "2106/2108 [============================>.] - ETA: 0s - loss: 4.3476 - accuracy: 0.1833WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 4.3480 - accuracy: 0.1833\n",
      "Epoch 20/100\n",
      "2107/2108 [============================>.] - ETA: 0s - loss: 4.2139 - accuracy: 0.2033WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 4.2139 - accuracy: 0.2033\n",
      "Epoch 21/100\n",
      "2105/2108 [============================>.] - ETA: 0s - loss: 4.0899 - accuracy: 0.2235WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 4.0899 - accuracy: 0.2235\n",
      "Epoch 22/100\n",
      "2107/2108 [============================>.] - ETA: 0s - loss: 3.9697 - accuracy: 0.2445WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 3.9697 - accuracy: 0.2445\n",
      "Epoch 23/100\n",
      "2106/2108 [============================>.] - ETA: 0s - loss: 3.8587 - accuracy: 0.2635WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 3.8588 - accuracy: 0.2635\n",
      "Epoch 24/100\n",
      "2105/2108 [============================>.] - ETA: 0s - loss: 3.7522 - accuracy: 0.2809WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 3.7525 - accuracy: 0.2808\n",
      "Epoch 25/100\n",
      "2105/2108 [============================>.] - ETA: 0s - loss: 3.6514 - accuracy: 0.2981WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 3.6517 - accuracy: 0.2980\n",
      "Epoch 26/100\n",
      "2108/2108 [==============================] - ETA: 0s - loss: 3.5581 - accuracy: 0.3131WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2108/2108 [==============================] - 30s 14ms/step - loss: 3.5581 - accuracy: 0.3131\n",
      "Epoch 27/100\n",
      "2106/2108 [============================>.] - ETA: 0s - loss: 3.4653 - accuracy: 0.3290WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 3.4650 - accuracy: 0.3290\n",
      "Epoch 28/100\n",
      "2106/2108 [============================>.] - ETA: 0s - loss: 3.3788 - accuracy: 0.3442WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 3.3786 - accuracy: 0.3443\n",
      "Epoch 29/100\n",
      "2105/2108 [============================>.] - ETA: 0s - loss: 3.2962 - accuracy: 0.3558WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 3.2961 - accuracy: 0.3558\n",
      "Epoch 30/100\n",
      "2106/2108 [============================>.] - ETA: 0s - loss: 3.2165 - accuracy: 0.3695WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 3.2166 - accuracy: 0.3694\n",
      "Epoch 31/100\n",
      "2106/2108 [============================>.] - ETA: 0s - loss: 3.1394 - accuracy: 0.3817WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 3.1394 - accuracy: 0.3817\n",
      "Epoch 32/100\n",
      "2107/2108 [============================>.] - ETA: 0s - loss: 3.0664 - accuracy: 0.3936WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 3.0664 - accuracy: 0.3937\n",
      "Epoch 33/100\n",
      "2106/2108 [============================>.] - ETA: 0s - loss: 2.9957 - accuracy: 0.4043WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 2.9958 - accuracy: 0.4043\n",
      "Epoch 34/100\n",
      "2105/2108 [============================>.] - ETA: 0s - loss: 2.9303 - accuracy: 0.4161WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 2.9306 - accuracy: 0.4161\n",
      "Epoch 35/100\n",
      "2106/2108 [============================>.] - ETA: 0s - loss: 2.8623 - accuracy: 0.4269WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 31s 15ms/step - loss: 2.8627 - accuracy: 0.4268\n",
      "Epoch 36/100\n",
      "2105/2108 [============================>.] - ETA: 0s - loss: 2.8054 - accuracy: 0.4356WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 2.8054 - accuracy: 0.4356\n",
      "Epoch 37/100\n",
      "2104/2108 [============================>.] - ETA: 0s - loss: 2.7438 - accuracy: 0.4471WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 2.7443 - accuracy: 0.4469\n",
      "Epoch 38/100\n",
      "2106/2108 [============================>.] - ETA: 0s - loss: 2.6879 - accuracy: 0.4547WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 2.6881 - accuracy: 0.4546\n",
      "Epoch 39/100\n",
      "2105/2108 [============================>.] - ETA: 0s - loss: 2.6309 - accuracy: 0.4646WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 31s 15ms/step - loss: 2.6308 - accuracy: 0.4646\n",
      "Epoch 40/100\n",
      "2108/2108 [==============================] - ETA: 0s - loss: 2.5810 - accuracy: 0.4733WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 2.5810 - accuracy: 0.4733\n",
      "Epoch 41/100\n",
      "2106/2108 [============================>.] - ETA: 0s - loss: 2.5270 - accuracy: 0.4833WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 2.5272 - accuracy: 0.4833\n",
      "Epoch 42/100\n",
      "2105/2108 [============================>.] - ETA: 0s - loss: 2.4770 - accuracy: 0.4918WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 2.4772 - accuracy: 0.4918\n",
      "Epoch 43/100\n",
      "2108/2108 [==============================] - ETA: 0s - loss: 2.4290 - accuracy: 0.5012WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 2.4290 - accuracy: 0.5012\n",
      "Epoch 44/100\n",
      "2108/2108 [==============================] - ETA: 0s - loss: 2.3845 - accuracy: 0.5073WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 2.3845 - accuracy: 0.5073\n",
      "Epoch 45/100\n",
      "2107/2108 [============================>.] - ETA: 0s - loss: 2.3371 - accuracy: 0.5179WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 2.3371 - accuracy: 0.5179\n",
      "Epoch 46/100\n",
      "2107/2108 [============================>.] - ETA: 0s - loss: 2.2963 - accuracy: 0.5255WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 2.2963 - accuracy: 0.5255\n",
      "Epoch 47/100\n",
      "2106/2108 [============================>.] - ETA: 0s - loss: 2.2547 - accuracy: 0.5307WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 2.2547 - accuracy: 0.5308\n",
      "Epoch 48/100\n",
      "2104/2108 [============================>.] - ETA: 0s - loss: 2.2130 - accuracy: 0.5385WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 2.2134 - accuracy: 0.5384\n",
      "Epoch 49/100\n",
      "2106/2108 [============================>.] - ETA: 0s - loss: 2.1747 - accuracy: 0.5450WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 2.1746 - accuracy: 0.5450\n",
      "Epoch 50/100\n",
      "2108/2108 [==============================] - ETA: 0s - loss: 2.1343 - accuracy: 0.5539WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 2.1343 - accuracy: 0.5539\n",
      "Epoch 51/100\n",
      "2106/2108 [============================>.] - ETA: 0s - loss: 2.1012 - accuracy: 0.5586WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 2.1010 - accuracy: 0.5587\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2108/2108 [==============================] - ETA: 0s - loss: 2.0654 - accuracy: 0.5655WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 2.0654 - accuracy: 0.5655\n",
      "Epoch 53/100\n",
      "2107/2108 [============================>.] - ETA: 0s - loss: 2.0265 - accuracy: 0.5733WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 31s 14ms/step - loss: 2.0266 - accuracy: 0.5733\n",
      "Epoch 54/100\n",
      "2104/2108 [============================>.] - ETA: 0s - loss: 1.9979 - accuracy: 0.5797WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 1.9984 - accuracy: 0.5795\n",
      "Epoch 55/100\n",
      "2107/2108 [============================>.] - ETA: 0s - loss: 1.9644 - accuracy: 0.5857WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 30s 14ms/step - loss: 1.9644 - accuracy: 0.5857\n",
      "Epoch 56/100\n",
      "2106/2108 [============================>.] - ETA: 0s - loss: 1.9314 - accuracy: 0.5924WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2108/2108 [==============================] - 29s 14ms/step - loss: 1.9315 - accuracy: 0.5924\n",
      "Epoch 57/100\n",
      " 430/2108 [=====>........................] - ETA: 24s - loss: 1.7910 - accuracy: 0.6257"
     ]
    }
   ],
   "source": [
    "predictors, label, max_sequence_len, total_words = dataset_preparation(data)\n",
    "model = create_model(predictors, label, max_sequence_len, total_words)\n",
    "print( generate_text(\"we naughty\", 3, max_sequence_len) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f21501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
